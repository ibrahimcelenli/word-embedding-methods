{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/word2vec.png\",width=800,height=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "progressbar.streams.wrap_stderr()\n",
    "\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 2\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_word_freqs(split_text, subsampling = False, sampling_rate = 0.001):\n",
    "    vocab = {}\n",
    "    word_to_ix = {}\n",
    "    total = 0.0\n",
    "    for word in split_text:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 0\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "        vocab[word] += 1.0\n",
    "        total += 1.0\n",
    "    if subsampling:\n",
    "        for i, word in enumerate(split_text):\n",
    "            val = np.sqrt(total / vocab[word])\n",
    "            prob = val * (1 + val)\n",
    "            sampling = np.random.sample()\n",
    "            if (sampling <= prob):\n",
    "                del [split_text[i]]\n",
    "                i -= 1\n",
    "    return split_text, vocab, word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_training_data(split_text, word_to_ix, context_size, model_type = \"skipgram\"):\n",
    "    training_data = []\n",
    "    for i, word in enumerate(split_text):\n",
    "        if (model_type == \"skipgram\"):\n",
    "            back_i = i - 1\n",
    "            back_c = 0\n",
    "            forw_i = i + 1\n",
    "            forw_c = 0\n",
    "            while (back_i >= 0 and back_c < context_size):\n",
    "                training_data.append(([word_to_ix[word]], word_to_ix[split_text[back_i]]))\n",
    "                back_i -= 1\n",
    "                back_c += 1\n",
    "            while (forw_i < len(split_text) and forw_c < context_size):\n",
    "                training_data.append(([word_to_ix[word]], word_to_ix[split_text[forw_i]]))\n",
    "                forw_i += 1\n",
    "                forw_c += 1\n",
    "        elif (model_type == \"cbow\"):\n",
    "            point = []\n",
    "            back_i = i - 1\n",
    "            back_c = 0\n",
    "            forw_i = i + 1\n",
    "            forw_c = 0\n",
    "            while (back_i >= 0 and back_c < context_size):\n",
    "                point.append(word_to_ix[split_text[back_i]])\n",
    "                back_i -= 1\n",
    "                back_c += 1\n",
    "            while (forw_i < len(split_text) and forw_c < context_size):\n",
    "                point.append(word_to_ix[split_text[forw_i]])\n",
    "                forw_i += 1\n",
    "                forw_c += 1\n",
    "            training_data.append((point, word_to_ix[word]))\n",
    "        else:\n",
    "            raise ValueError(\"Inappropriate argument value for model_type - either `skipgram` or `cbow`.\")\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skipgram(context_size, model_type = \"skipgram\", subsampling = False, sampling_rate = 0.001):\n",
    "    \n",
    "    processed_text = \"\"\"superonline bir milyon evin kapisina fiber internet goturdu bizde niye \n",
    "    yok bize niye getirmiyorlar bir evde olmamasi gereken   şeyturkcell   digiturk keriz anten çiçeği\n",
    "    en ucuz iphone s fiyatını hangi operatör sunuyor ohasın\"\"\".split()\n",
    "    \n",
    "    print(\"processed_text : \\n\",processed_text,\"\\n\")\n",
    "    \n",
    "    new_processed_text, vocab, word_to_ix = gather_word_freqs(processed_text,subsampling = subsampling, sampling_rate = sampling_rate)\n",
    "    \n",
    "    \n",
    "    print(\"new processed_text : \\n\",new_processed_text,\"\\n\")\n",
    "    print(\"vocab : \\n\",vocab,\"\\n\")\n",
    "    print(\"word_to_ix : \\n\",word_to_ix,\"\\n\")\n",
    "    \n",
    "    training_data = gather_training_data(new_processed_text, word_to_ix, context_size ,model_type = model_type)\n",
    "    print(\"training_data : \\n\",training_data,\"\\n\")\n",
    "    \n",
    "    return new_processed_text, vocab, word_to_ix, training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cbow(context_size, model_type = \"cbow\", subsampling = False, sampling_rate = 0.001):\n",
    "    \n",
    "    processed_text = \"\"\"superonline bir milyon evin kapisina fiber internet goturdu bizde niye \n",
    "    yok bize niye getirmiyorlar bir evde olmamasi gereken   şeyturkcell   digiturk keriz anten çiçeği\n",
    "    en ucuz iphone s fiyatını hangi operatör sunuyor ohasın\"\"\".split()\n",
    "    \n",
    "    print(\"processed_text : \\n\",processed_text,\"\\n\")\n",
    "    \n",
    "    new_processed_text, vocab, word_to_ix = gather_word_freqs(processed_text,subsampling = subsampling, sampling_rate = sampling_rate)\n",
    "    print(\"new_processed_text : \\n\",new_processed_text,\"\\n\")\n",
    "    print(\"vocab : \\n\",vocab,\"\\n\")\n",
    "    print(\"word_to_ix : \\n\",word_to_ix,\"\\n\")\n",
    "    \n",
    "    training_data = gather_training_data(new_processed_text, word_to_ix, context_size ,model_type = model_type)\n",
    "    print(\"training_data : \\n\",training_data,\"\\n\")\n",
    "    \n",
    "    return new_processed_text, vocab, word_to_ix, training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "''' Continuous bag-of-words model for word2vec.\n",
    "\n",
    "Parameters:\n",
    "    vocab_size: number of defined words in the vocab\n",
    "    embedding_dim: desired embedded vector dimension\n",
    "    context_size: number of context words used\n",
    "\n",
    "'''\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = torch.mean(self.embeddings(inputs), dim=0).view((1, -1))\n",
    "        out = self.linear(embeds)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "''' Skip-gram bag-of-words model for word2vec.\n",
    "\n",
    "Parameters:\n",
    "    vocab_size: number of defined words in the vocab\n",
    "    embedding_dim: desired embedded vector dimension\n",
    "\n",
    "'''\n",
    "class SkipGram(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = self.linear(embeds)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_text : \n",
      " ['superonline', 'bir', 'milyon', 'evin', 'kapisina', 'fiber', 'internet', 'goturdu', 'bizde', 'niye', 'yok', 'bize', 'niye', 'getirmiyorlar', 'bir', 'evde', 'olmamasi', 'gereken', 'şeyturkcell', 'digiturk', 'keriz', 'anten', 'çiçeği', 'en', 'ucuz', 'iphone', 's', 'fiyatını', 'hangi', 'operatör', 'sunuyor', 'ohasın'] \n",
      "\n",
      "new processed_text : \n",
      " ['bir', 'evin', 'fiber', 'goturdu', 'niye', 'bize', 'getirmiyorlar', 'evde', 'gereken', 'digiturk', 'anten', 'en', 'iphone', 'fiyatını', 'operatör', 'ohasın'] \n",
      "\n",
      "vocab : \n",
      " {'superonline': 1.0, 'bir': 2.0, 'milyon': 1.0, 'evin': 1.0, 'kapisina': 1.0, 'fiber': 1.0, 'internet': 1.0, 'goturdu': 1.0, 'bizde': 1.0, 'niye': 2.0, 'yok': 1.0, 'bize': 1.0, 'getirmiyorlar': 1.0, 'evde': 1.0, 'olmamasi': 1.0, 'gereken': 1.0, 'şeyturkcell': 1.0, 'digiturk': 1.0, 'keriz': 1.0, 'anten': 1.0, 'çiçeği': 1.0, 'en': 1.0, 'ucuz': 1.0, 'iphone': 1.0, 's': 1.0, 'fiyatını': 1.0, 'hangi': 1.0, 'operatör': 1.0, 'sunuyor': 1.0, 'ohasın': 1.0} \n",
      "\n",
      "word_to_ix : \n",
      " {'superonline': 0, 'bir': 1, 'milyon': 2, 'evin': 3, 'kapisina': 4, 'fiber': 5, 'internet': 6, 'goturdu': 7, 'bizde': 8, 'niye': 9, 'yok': 10, 'bize': 11, 'getirmiyorlar': 12, 'evde': 13, 'olmamasi': 14, 'gereken': 15, 'şeyturkcell': 16, 'digiturk': 17, 'keriz': 18, 'anten': 19, 'çiçeği': 20, 'en': 21, 'ucuz': 22, 'iphone': 23, 's': 24, 'fiyatını': 25, 'hangi': 26, 'operatör': 27, 'sunuyor': 28, 'ohasın': 29} \n",
      "\n",
      "training_data : \n",
      " [([1], 3), ([1], 5), ([3], 1), ([3], 5), ([3], 7), ([5], 3), ([5], 1), ([5], 7), ([5], 9), ([7], 5), ([7], 3), ([7], 9), ([7], 11), ([9], 7), ([9], 5), ([9], 11), ([9], 12), ([11], 9), ([11], 7), ([11], 12), ([11], 13), ([12], 11), ([12], 9), ([12], 13), ([12], 15), ([13], 12), ([13], 11), ([13], 15), ([13], 17), ([15], 13), ([15], 12), ([15], 17), ([15], 19), ([17], 15), ([17], 13), ([17], 19), ([17], 21), ([19], 17), ([19], 15), ([19], 21), ([19], 23), ([21], 19), ([21], 17), ([21], 23), ([21], 25), ([23], 21), ([23], 19), ([23], 25), ([23], 27), ([25], 23), ([25], 21), ([25], 27), ([25], 29), ([27], 25), ([27], 23), ([27], 29), ([29], 27), ([29], 25)] \n",
      "\n",
      "SkipGram(\n",
      "  (embeddings): Embedding(30, 2)\n",
      "  (linear): Linear(in_features=2, out_features=30, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#skipgram\n",
    "\n",
    "processed_text, vocab, word_to_ix, training_data = skipgram(CONTEXT_SIZE, model_type=\"skipgram\", subsampling=True, sampling_rate=0.001)\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()  #negative log likelihood loss\n",
    "model = SkipGram(len(vocab), EMBEDDING_DIM)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#skipgram\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  #Stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Beginning epoch 0\n",
      "context [1]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [1]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "Epoch 0 Loss: 214.05908\n",
      "Beginning epoch 1\n",
      "context [1]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [1]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "Epoch 1 Loss: 213.83026\n",
      "Beginning epoch 2\n",
      "context [1]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [1]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "Epoch 2 Loss: 213.60249\n",
      "Beginning epoch 3\n",
      "context [1]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [1]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "Epoch 3 Loss: 213.37589\n",
      "Beginning epoch 4\n",
      "context [1]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [1]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [3]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 1\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [5]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 3\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [7]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 5\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [9]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 7\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [11]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 9\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [12]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 11\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [13]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 12\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [15]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 13\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [17]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 15\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [19]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 17\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [21]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 19\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [23]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 21\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [25]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 23\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [27]\n",
      "target 29\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 27\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "context [29]\n",
      "target 25\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "Epoch 4 Loss: 213.15042\n"
     ]
    }
   ],
   "source": [
    "#skipgram\n",
    "print (\"Starting training\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    print (\"Beginning epoch %d\" % epoch)\n",
    "    progress_bar = progressbar.ProgressBar()\n",
    "    for context, target in progress_bar(training_data):\n",
    "        print(\"context\",context)\n",
    "        print(\"target\",target)\n",
    "        print(\"\\n\",\"*\"*50,\"\\n\")\n",
    "        context_var = autograd.Variable(torch.LongTensor(context))\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_var)\n",
    "        loss = loss_function(log_probs, autograd.Variable(\n",
    "            torch.LongTensor([target])))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "    print (\"Epoch %d Loss: %.5f\" % (epoch, total_loss[0]))\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_text : \n",
      " ['superonline', 'bir', 'milyon', 'evin', 'kapisina', 'fiber', 'internet', 'goturdu', 'bizde', 'niye', 'yok', 'bize', 'niye', 'getirmiyorlar', 'bir', 'evde', 'olmamasi', 'gereken', 'şeyturkcell', 'digiturk', 'keriz', 'anten', 'çiçeği', 'en', 'ucuz', 'iphone', 's', 'fiyatını', 'hangi', 'operatör', 'sunuyor', 'ohasın'] \n",
      "\n",
      "new_processed_text : \n",
      " ['bir', 'evin', 'fiber', 'goturdu', 'niye', 'bize', 'getirmiyorlar', 'evde', 'gereken', 'digiturk', 'anten', 'en', 'iphone', 'fiyatını', 'operatör', 'ohasın'] \n",
      "\n",
      "vocab : \n",
      " {'superonline': 1.0, 'bir': 2.0, 'milyon': 1.0, 'evin': 1.0, 'kapisina': 1.0, 'fiber': 1.0, 'internet': 1.0, 'goturdu': 1.0, 'bizde': 1.0, 'niye': 2.0, 'yok': 1.0, 'bize': 1.0, 'getirmiyorlar': 1.0, 'evde': 1.0, 'olmamasi': 1.0, 'gereken': 1.0, 'şeyturkcell': 1.0, 'digiturk': 1.0, 'keriz': 1.0, 'anten': 1.0, 'çiçeği': 1.0, 'en': 1.0, 'ucuz': 1.0, 'iphone': 1.0, 's': 1.0, 'fiyatını': 1.0, 'hangi': 1.0, 'operatör': 1.0, 'sunuyor': 1.0, 'ohasın': 1.0} \n",
      "\n",
      "word_to_ix : \n",
      " {'superonline': 0, 'bir': 1, 'milyon': 2, 'evin': 3, 'kapisina': 4, 'fiber': 5, 'internet': 6, 'goturdu': 7, 'bizde': 8, 'niye': 9, 'yok': 10, 'bize': 11, 'getirmiyorlar': 12, 'evde': 13, 'olmamasi': 14, 'gereken': 15, 'şeyturkcell': 16, 'digiturk': 17, 'keriz': 18, 'anten': 19, 'çiçeği': 20, 'en': 21, 'ucuz': 22, 'iphone': 23, 's': 24, 'fiyatını': 25, 'hangi': 26, 'operatör': 27, 'sunuyor': 28, 'ohasın': 29} \n",
      "\n",
      "training_data : \n",
      " [([3, 5], 1), ([1, 5, 7], 3), ([3, 1, 7, 9], 5), ([5, 3, 9, 11], 7), ([7, 5, 11, 12], 9), ([9, 7, 12, 13], 11), ([11, 9, 13, 15], 12), ([12, 11, 15, 17], 13), ([13, 12, 17, 19], 15), ([15, 13, 19, 21], 17), ([17, 15, 21, 23], 19), ([19, 17, 23, 25], 21), ([21, 19, 25, 27], 23), ([23, 21, 27, 29], 25), ([25, 23, 29], 27), ([27, 25], 29)] \n",
      "\n",
      "CBOW(\n",
      "  (embeddings): Embedding(30, 2)\n",
      "  (linear): Linear(in_features=2, out_features=30, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#cbow\n",
    "processed_text, vocab, word_to_ix, training_data = cbow(CONTEXT_SIZE, model_type=\"cbow\", subsampling=True, sampling_rate=0.001)\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cbow\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Beginning epoch 0\n",
      "Epoch 0 Loss: 57.29324\n",
      "Beginning epoch 1\n",
      "Epoch 1 Loss: 57.27409\n",
      "Beginning epoch 2\n",
      "Epoch 2 Loss: 57.25497\n",
      "Beginning epoch 3\n",
      "Epoch 3 Loss: 57.23587\n",
      "Beginning epoch 4\n",
      "Epoch 4 Loss: 57.21682\n"
     ]
    }
   ],
   "source": [
    "#cbow\n",
    "print (\"Starting training\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    print (\"Beginning epoch %d\" % epoch)\n",
    "    progress_bar = progressbar.ProgressBar()\n",
    "    for context, target in progress_bar(training_data):\n",
    "        context_var = autograd.Variable(torch.LongTensor(context))\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_var)\n",
    "        loss = loss_function(log_probs, autograd.Variable(\n",
    "            torch.LongTensor([target])))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "    print (\"Epoch %d Loss: %.5f\" % (epoch, total_loss[0]))\n",
    "    losses.append(total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
